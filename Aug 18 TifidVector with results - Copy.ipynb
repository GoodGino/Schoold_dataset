{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from datetime import datetime\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from collections import Counter\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read 100000 random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('video_products_100000_sample.csv',\n",
    "                   encoding='utf-8',  \n",
    "                    engine='python',\n",
    "                   memory_map=True,\n",
    "                   error_bad_lines=False,\n",
    "                    na_values='NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "text=data['review_body'].values\n",
    "star=data['star_rating']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Select the first 100000 data sample\n",
    "old=data.loc[:100000]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Write the random sample to desk\n",
    "new.to_csv('sample1.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data1= data[['review_body','star_rating','review_headline','pos_neg']]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Random select 100000 data sample\n",
    "new_sample=data.sample(n=100000)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Write the random sample to desk\n",
    "new_sample.to_csv('video_products_100000_sample.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X=data['review_body'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y=data['star_rating']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# split positive and negative review based on rating\n",
    "data['pos_neg']=['Positive' if x> 3 else 'Negative' for x in data.star_rating]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "y=data['pos_neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# TfidfVectorizer: ngram_range=(1,2),stop_words='english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 3429605)\n",
      "0:00:42.242206\n"
     ]
    }
   ],
   "source": [
    "#TfidfVectorizer\n",
    "t1 = datetime.now()\n",
    "vect=TfidfVectorizer(ngram_range=(1,2),stop_words='english')\n",
    "train_dtm = vect.fit_transform(X)\n",
    "print(train_dtm.shape)\n",
    "print(datetime.now() - t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the original data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the original data sample\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_dtm, y ,\n",
    "                                                    test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<70000x3429605 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 7685159 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling on training data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#RandomUnderSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "t1 = datetime.now()\n",
    "print('Original dataset shape {}'.format(Counter(y_train)))\n",
    "rus = RandomUnderSampler(random_state=100)\n",
    "X_res, y_res = rus.fit_sample(X_train, y_train)\n",
    "print('Resampled dataset shape {}'.format(Counter(y_res)))\n",
    "print(datetime.now() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({5: 41824, 4: 13372, 3: 6452, 1: 4959, 2: 3393})\n",
      "Resampled dataset shape Counter({5: 41824, 2: 41824, 1: 41824, 4: 41824, 3: 41824})\n",
      "0:01:29.649104\n"
     ]
    }
   ],
   "source": [
    "# Perform SMOTE on training set only\n",
    "t1 = datetime.now()\n",
    "print('Original dataset shape {}'.format(Counter(y_train)))\n",
    "sm = SMOTE(random_state=100)\n",
    "X_res, y_res = sm.fit_sample(X_train, y_train) \n",
    "print('Resampled dataset shape {}'.format(Counter(y_res)))\n",
    "print(datetime.now() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Test on original imbalanced data sample"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "# Naive Bayes \n",
    "# imbalanced\n",
    "t1 = datetime.now()\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred_class = nb.predict(X_test)\n",
    "print(classification_report(y_test,y_pred_class))\n",
    "print(datetime.now() - t1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#LinearSVC\n",
    "# imbalanced\n",
    "t1 = datetime.now()\n",
    "lin_clf = LinearSVC()\n",
    "clf=lin_clf.fit(X_train, y_train)\n",
    "y_pred_class = clf.predict(X_test)\n",
    "print(classification_report(y_test,y_pred_class))\n",
    "print(datetime.now() - t1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#LogisticRegression\n",
    "# imbalanced\n",
    "t1 = datetime.now()\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_class = logreg.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred_class))\n",
    "print(datetime.now() - t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on balanced data sample"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Naive Bayes \n",
    "# balanced\n",
    "t1 = datetime.now()\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_res, y_res)\n",
    "y_pred_class = nb.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred_class))\n",
    "print(classification_report(y_test,y_pred_class))\n",
    "print(confusion_matrix(y_test,y_pred_class))\n",
    "\n",
    "print(datetime.now() - t1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#LinearSVC\n",
    "# balanced\n",
    "t1 = datetime.now()\n",
    "lin_clf = LinearSVC()\n",
    "clf=lin_clf.fit(X_res, y_res)\n",
    "y_pred_class = clf.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred_class))\n",
    "print(classification_report(y_test,y_pred_class))\n",
    "print(confusion_matrix(y_test,y_pred_class))\n",
    "\n",
    "print(datetime.now() - t1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "source": [
    "#LogisticRegression\n",
    "# balanced\n",
    "t1 = datetime.now()\n",
    "logreg = LogisticRegression()\n",
    "logreg = logreg.fit(X_res, y_res)\n",
    "y_pred_class = logreg.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred_class))\n",
    "print(classification_report(y_test,y_pred_class))\n",
    "print(confusion_matrix(y_test,y_pred_class))\n",
    "\n",
    "print(datetime.now() - t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10-fold cross validation on resample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation average accuracy: 0.596\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.00      0.00      0.00      2157\n",
      "          2       0.00      0.00      0.00      1487\n",
      "          3       0.00      0.00      0.00      2723\n",
      "          4       0.00      0.00      0.00      5739\n",
      "          5       0.60      1.00      0.75     17894\n",
      "\n",
      "avg / total       0.36      0.60      0.45     30000\n",
      "\n",
      "[[    0     0     0     0  2157]\n",
      " [    0     0     0     0  1487]\n",
      " [    0     0     0     0  2723]\n",
      " [    0     0     0     0  5739]\n",
      " [    0     0     0     0 17894]]\n",
      "0:00:11.794410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes 10-fold cross validation \n",
    "# balanced\n",
    "t1 = datetime.now()\n",
    "nb = MultinomialNB()\n",
    "nb = nb.fit(X_res, y_res)\n",
    "y_pred_class = cross_validation.cross_val_predict(nb,X_test,y_test,cv=10)\n",
    "\n",
    "print(\"10-fold cross validation average accuracy: %.3f\" %accuracy_score(y_test,y_pred_class))\n",
    "print(classification_report(y_test,y_pred_class))\n",
    "print(confusion_matrix(y_test,y_pred_class))\n",
    "\n",
    "print(datetime.now() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation average accuracy: 0.638\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      0.42      0.51      2157\n",
      "          2       0.40      0.03      0.06      1487\n",
      "          3       0.36      0.06      0.11      2723\n",
      "          4       0.35      0.12      0.18      5739\n",
      "          5       0.67      0.97      0.79     17894\n",
      "\n",
      "avg / total       0.56      0.64      0.55     30000\n",
      "\n",
      "[[  900    39    58   116  1044]\n",
      " [  237    46   115   220   869]\n",
      " [   99    22   176   522  1904]\n",
      " [   39     2   101   710  4887]\n",
      " [   68     6    45   474 17301]]\n",
      "0:03:18.053622\n"
     ]
    }
   ],
   "source": [
    "#LinearSVC 10-fold cross validation \n",
    "# balanced\n",
    "t1 = datetime.now()\n",
    "lin_clf = LinearSVC()\n",
    "clf=lin_clf.fit(X_res, y_res)\n",
    "y_pred_class = cross_validation.cross_val_predict(clf,X_test,y_test,cv=10)\n",
    "\n",
    "print(\"10-fold cross validation average accuracy: %.3f\" %accuracy_score(y_test,y_pred_class))\n",
    "print(classification_report(y_test,y_pred_class))\n",
    "print(confusion_matrix(y_test,y_pred_class))\n",
    "\n",
    "print(datetime.now() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation average accuracy: 0.611\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.15      0.25      2157\n",
      "          2       0.00      0.00      0.00      1487\n",
      "          3       0.36      0.01      0.02      2723\n",
      "          4       0.32      0.04      0.07      5739\n",
      "          5       0.62      0.99      0.76     17894\n",
      "\n",
      "avg / total       0.52      0.61      0.49     30000\n",
      "\n",
      "[[  327     0     9    45  1776]\n",
      " [   48     0    13   109  1317]\n",
      " [   18     0    21   189  2495]\n",
      " [    6     0     7   219  5507]\n",
      " [   11     0     8   116 17759]]\n",
      "0:09:34.857134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression 10-fold cross validation \n",
    "# balanced\n",
    "t1 = datetime.now()\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg = logreg.fit(X_res, y_res)\n",
    "\n",
    "y_pred_class = cross_validation.cross_val_predict(logreg,X_test,y_test,cv=10)\n",
    "\n",
    "print(\"10-fold cross validation average accuracy: %.3f\" %accuracy_score(y_test,y_pred_class))\n",
    "print(classification_report(y_test,y_pred_class))\n",
    "print(confusion_matrix(y_test,y_pred_class))\n",
    "\n",
    "print(datetime.now() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
